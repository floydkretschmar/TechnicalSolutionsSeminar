\begin{frame}{Real world impact of ML in terms of fairness \cite{machinebias}}
    Discussions about fairness in ML are not theoretical: \\
    $\rightarrow$ \textbf{Machine Learning is already used every day to make decisions about peoples lives} \\~\\
    
    \textbf{Example:} Risk assessment tools used to predict the likelihood of committing a future crime
    \begin{itemize}
        \item used in multiple states across the USA
        \item have wide ranging impact on judicial process in the united states: \\
        setting bond amounts, pretrial release, sentencing and parole decisions
    \end{itemize}
    
    \begin{block}{Overall goal of these risk assessment tools}
        \enquote{If computers could accurately predict which defendants were likely to commit new crimes, the criminal justice system could be fairer and more selective about who is incarcerated and for how long.}
    \end{block}
\end{frame}

\begin{frame}{Real world impact of ML in terms of fairness \cite{machinebias}}
    \textbf{But:} \enquote{The trick, of course, is to make sure the computer gets it right.} \\~\\
    
    ProPublica obtained and analyzed risk scores of more than 7,000 people:
    
    \begin{itemize}
        \item \enquote{Only 20 percent of the people predicted to commit violent crimes actually went on to do so.}
        \item \enquote{Of those deemed likely to re-offend, \textbf{61 percent were arrested for any subsequent crimes} within two years.}
        \item \enquote{The formula was particularly \textbf{likely to falsely flag black defendants as future criminals}, wrongly labeling them this way at almost twice the rate as white defendants.}
        \item \enquote{\textbf{White defendants were mislabeled as low risk more often} than black defendants.}
    \end{itemize}
\end{frame}