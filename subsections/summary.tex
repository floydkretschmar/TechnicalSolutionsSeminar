In conclusion, all of the papers present the issue of fairness in machine
learning as a fairly complex one. Recognizing and exploiting patterns in 
data is at the very core of machine learning. If the underlying structures contain
discriminatory or biased patterns, this will be reflected in the resulting
algorithms. The goal has to be to find ways to quantify and operationalize
fairness in a way that makes these biases obvious and allows to account for
them. This becomes especially important, as these systems are used more
and more frequently to make decisions about peoples lives and that have long
lasting effects, like automated decision making systems used in the 
criminal justice system.