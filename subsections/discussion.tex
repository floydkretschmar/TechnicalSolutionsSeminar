Include additional work like: \cite{isabel01} (Isabel) \cite{isabel02} (Isabel) \cite{automatedDsicrimination} \cite{Singh} \cite{DBLP:conf/maics/RalescuR17} combining "disparate impact" with notation.

The authors of \cite{Berk.2018} argue that the discussion about fairness in machine learning 
is fundamentally a discussion about tradeoffs. They state that \enquote{\dots there will 
always be tradeoffs. These are mathematical facts subject to formal proofs. Denying that these
tradeoffs exist is not a solution.} \\
They argue that the problem at the heart of fairness in machine learning is the difference
in base rate across protected groups which \enquote{can cascade through fairness assessments
and lead to difficult tradoffs.} In terms of discussing these tradeoffs, the authors make multiple
suggestions:
\begin{itemize}
    \item The tradeoffs need to be explicitly represented and available as tuning parameters.
    \item Future measures of fairness should be formulated in such a way, that tradeoffs can
    be made with them.
    \item The determination of tradeoffs should ultimately fall in the hands of the stakeholders.
\end{itemize}
As a final point the paper states, that any solution will likely not come fast and no singular
solution will be able to reverse longstanding, institutionalized inequality.