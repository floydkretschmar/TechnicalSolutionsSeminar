Description of Fairness in ML (target variable/class labels, training data, feature selection, 
Proxies, Masking)

Defining any kind of target variable or class labels is always a very subjective process, where 
the presented problem could unintentionally be parsed in a way which systematically disadvantages 
certain classes \cite{Barocas.2016}. In addition to that, the training data could be biased by 
either considering cases in which prejudice has played a role or simply over- or underrepresenting 
a certain class \cite{Barocas.2016}. If this data gets used, it would lead to a discriminatory model. 
